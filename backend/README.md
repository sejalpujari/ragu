# Explainable RAG From Scratch â€“ Interactive Retrieval-Augmented Generation Demo

ðŸ§  A **fully transparent, from-scratch** Retrieval-Augmented Generation (RAG) application built with **Python**, **Streamlit**, **Sentence Transformers**, and **Groq** for fast LLM inference.

This project demonstrates core RAG concepts without relying on high-level frameworks like LangChain or LlamaIndex â€” perfect for learning how embeddings, chunking, vector similarity, and context-augmented generation actually work under the hood.

https://github.com/**yourusername**/explainable-rag-from-scratch

## âœ¨ Features

- **End-to-end from-scratch RAG pipeline**:
  - Document loading
  - Custom character-based chunking with configurable size & overlap
  - Embeddings using `all-MiniLM-L6-v2` (384 dimensions)
  - Pure NumPy cosine similarity retrieval (no vector DB)
  - Top-k context selection
  - Prompt augmentation + generation via Groq API
- **Fully interactive & explainable Streamlit UI** showing every step:
  - Raw documents
  - All created chunks
  - Chunk & query embedding previews
  - Similarity scores for every chunk
  - Top retrieved chunks
  - Final context sent to LLM
  - Generated answer
- Real-time parameter tuning via sidebar sliders:
  - Chunk size (50â€“800 characters)
  - Chunk overlap (0â€“300 characters)
  - Top-k retrieved chunks (1â€“12)
- Fast inference using **Groq** (supports Llama-3.1, Mixtral, Gemma2, etc.)
- Strict "use only provided context" prompting â†’ minimizes hallucinations

## Demo Screenshots

(Add 3â€“5 screenshots here later â€“ e.g. full UI, similarity scores expander, final answer section)

1. Main interface with sliders and query  
2. Chunk & embedding visualization  
3. Top-k retrieved chunks + final context  
4. Generated answer example

## Project Structure

```text
.
â”œâ”€â”€ data/                    # Put your .txt documents here
â”‚   â”œâ”€â”€ rag.txt
â”‚   â”œâ”€â”€ llm.txt
â”‚   â””â”€â”€ ai.txt
â”œâ”€â”€ .env                     # GROQ_API_KEY=...
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ ui.py                    # â† Main Streamlit application
â”œâ”€â”€ rag_pipeline.py          # Core RAG logic (chunk â†’ embed â†’ retrieve)
â”œâ”€â”€ chunker.py               # Simple overlapping chunker
â”œâ”€â”€ embed_store.py           # SentenceTransformer wrapper
â”œâ”€â”€ retrieve.py              # Cosine similarity + top-k
â”œâ”€â”€ llm.py                   # Groq client + RAG prompt
â””â”€â”€ README.md

2. Installation
Bash# Clone the repo
git clone https://github.com/yourusername/explainable-rag-from-scratch.git
cd explainable-rag-from-scratch

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate    # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file and add your key
USE THIS WEBSITE AND CREATE A GROQ API KEY https://groq.com/
echo "GROQ_API_KEY=gsk_..." > .env
3. Run the app
Bashstreamlit run ui.py
Open http://localhost:8501 in your browser.